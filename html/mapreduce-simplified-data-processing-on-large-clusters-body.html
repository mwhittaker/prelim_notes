<h1 id="mapreduce-simplified-data-processing-on-large-clusters">MapReduce: simplified data processing on large clusters</h1>
<ul>
<li>map: (k1, v1) -&gt; (k2, v2)</li>
<li>reduce: (k2, v2 list) -&gt; v2 list</li>
<li>Implementation
<ul>
<li>Single master, multiple mappers, multiple reducers</li>
<li>Split input and distribute to mappers</li>
<li>Mapper writes locally and informs master of write location</li>
<li>Reducers get location info from master and external sort data when ready</li>
<li>Reducers run reduce and create a file for each output</li>
</ul></li>
<li>Master stores status of each task and the position of the reducer data</li>
<li>If a worker dies (determined via a heartbeat), then the master re-runs the job and informs reducers to re-read data</li>
<li>More tasks means less skew but more memory pressure on the master</li>
<li>Backup tasks for stragglers</li>
<li>Refinements
<ul>
<li>Custom partition functions</li>
<li>Combiner functions</li>
<li>Skip records which cause failures</li>
<li>Local execution for debugging</li>
<li>Status info in HTML</li>
<li>Counters</li>
</ul></li>
</ul>
